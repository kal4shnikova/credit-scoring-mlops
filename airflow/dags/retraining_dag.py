"""
Airflow DAG –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
–≠—Ç–∞–ø 7: –ü–∞–π–ø–ª–∞–π–Ω –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –∏ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è
"""

from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.providers.cncf.kubernetes.operators.kubernetes_pod import KubernetesPodOperator
from airflow.sensors.external_task import ExternalTaskSensor
from airflow.utils.dates import days_ago
from datetime import timedelta
import logging

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è DAG
default_args = {
    'owner': 'ml-team',
    'depends_on_past': False,
    'email': ['ml-alerts@example.com'],
    'email_on_failure': True,
    'email_on_retry': False,
    'retries': 2,
    'retry_delay': timedelta(minutes=5),
}

dag = DAG(
    'credit_scoring_retraining',
    default_args=default_args,
    description='Automated retraining pipeline for credit scoring model',
    schedule_interval='@weekly',  # –ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ
    start_date=days_ago(1),
    catchup=False,
    tags=['ml', 'credit-scoring', 'retraining'],
)


# ============================================
# Task 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—Ä–∏—Ñ—Ç–∞
# ============================================

def check_drift(**context):
    """
    –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –¥—Ä–∏—Ñ—Ç–∞ –≤ –¥–∞–Ω–Ω—ã—Ö
    –ï—Å–ª–∏ –¥—Ä–∏—Ñ—Ç –æ–±–Ω–∞—Ä—É–∂–µ–Ω - –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω
    """
    logging.info("Checking for data drift...")
    
    # –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ª–æ–≥–∏–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥—Ä–∏—Ñ—Ç–∞
    # –î–ª—è –ø—Ä–∏–º–µ—Ä–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–∫–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    
    from monitoring.evidently.drift_detection import DriftMonitor
    
    monitor = DriftMonitor(
        reference_data_path='data/processed/train.csv',
        current_data_path='data/processed/current.csv'
    )
    
    drift_metrics = monitor.get_drift_metrics()
    should_retrain = monitor.should_retrain(drift_threshold=0.3)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ XCom –¥–ª—è —Å–ª–µ–¥—É—é—â–∏—Ö –∑–∞–¥–∞—á
    context['task_instance'].xcom_push(key='drift_detected', value=should_retrain)
    context['task_instance'].xcom_push(key='drift_score', value=drift_metrics['dataset_drift_score'])
    
    logging.info(f"Drift score: {drift_metrics['dataset_drift_score']:.2%}")
    logging.info(f"Should retrain: {should_retrain}")
    
    return should_retrain


check_drift_task = PythonOperator(
    task_id='check_drift',
    python_callable=check_drift,
    dag=dag,
)


# ============================================
# Task 2: –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
# ============================================

def fetch_new_data(**context):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ production"""
    logging.info("Fetching new training data from production...")
    
    # –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ª–æ–≥–∏–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ production –ë–î
    # –î–ª—è –ø—Ä–∏–º–µ—Ä–∞ —Å–æ–∑–¥–∞–µ–º –∑–∞–≥–ª—É—à–∫—É
    
    import pandas as pd
    import numpy as np
    
    # –°–∏–º—É–ª—è—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    np.random.seed(42)
    n_samples = 5000
    
    new_data = pd.DataFrame({
        'age': np.random.randint(18, 70, n_samples),
        'income': np.random.lognormal(10.5, 0.8, n_samples),
        'loan_amount': np.random.lognormal(9, 1, n_samples),
        'credit_history_length': np.random.randint(0, 30, n_samples),
        'num_open_accounts': np.random.randint(0, 15, n_samples),
        'debt_to_income': np.random.uniform(0, 1, n_samples),
        'num_late_payments': np.random.poisson(1, n_samples),
        'employment_length': np.random.randint(0, 40, n_samples),
        'num_credit_inquiries': np.random.poisson(2, n_samples),
        'credit_utilization': np.random.uniform(0, 1, n_samples),
        'default': np.random.binomial(1, 0.3, n_samples),
    })
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    new_data.to_csv('data/processed/new_train_data.csv', index=False)
    
    logging.info(f"Fetched {len(new_data)} new samples")
    
    return len(new_data)


fetch_data_task = PythonOperator(
    task_id='fetch_new_data',
    python_callable=fetch_new_data,
    dag=dag,
)


# ============================================
# Task 3: –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
# ============================================

def validate_data(**context):
    """–í–∞–ª–∏–¥–∞—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö"""
    logging.info("Validating data quality...")
    
    import pandas as pd
    
    df = pd.read_csv('data/processed/new_train_data.csv')
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∏
    checks = {
        'no_missing_values': df.isnull().sum().sum() == 0,
        'correct_dtypes': all(df.dtypes.apply(lambda x: x in ['int64', 'float64'])),
        'target_balance': 0.1 < df['default'].mean() < 0.9,
        'sufficient_samples': len(df) >= 1000,
    }
    
    all_passed = all(checks.values())
    
    for check, passed in checks.items():
        logging.info(f"  {check}: {'‚úÖ' if passed else '‚ùå'}")
    
    if not all_passed:
        raise ValueError("Data validation failed!")
    
    logging.info("Data validation passed ‚úÖ")
    
    return all_passed


validate_data_task = PythonOperator(
    task_id='validate_data',
    python_callable=validate_data,
    dag=dag,
)


# ============================================
# Task 4: –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
# ============================================

# –ò—Å–ø–æ–ª—å–∑—É–µ–º KubernetesPodOperator –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ–±—É—á–µ–Ω–∏—è –≤ Kubernetes
train_model_task = KubernetesPodOperator(
    task_id='train_model',
    name='model-training-job',
    namespace='default',
    image='ghcr.io/your-username/credit-scoring-trainer:latest',
    cmds=['python'],
    arguments=['models/training/train_nn.py'],
    labels={'app': 'model-training'},
    get_logs=True,
    is_delete_operator_pod=True,
    dag=dag,
)


# ============================================
# Task 5: –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ ONNX
# ============================================

convert_onnx_task = KubernetesPodOperator(
    task_id='convert_to_onnx',
    name='onnx-conversion-job',
    namespace='default',
    image='ghcr.io/your-username/credit-scoring-trainer:latest',
    cmds=['python'],
    arguments=['models/onnx/convert_to_onnx.py'],
    labels={'app': 'onnx-conversion'},
    get_logs=True,
    is_delete_operator_pod=True,
    dag=dag,
)


# ============================================
# Task 6: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
# ============================================

optimize_model_task = KubernetesPodOperator(
    task_id='optimize_model',
    name='model-optimization-job',
    namespace='default',
    image='ghcr.io/your-username/credit-scoring-trainer:latest',
    cmds=['python'],
    arguments=['models/optimization/quantize.py'],
    labels={'app': 'model-optimization'},
    get_logs=True,
    is_delete_operator_pod=True,
    dag=dag,
)


# ============================================
# Task 7: –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏
# ============================================

def validate_model(**context):
    """–í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏"""
    logging.info("Validating new model performance...")
    
    # –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ª–æ–≥–∏–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–æ–≤–∞—è –º–æ–¥–µ–ª—å –Ω–µ —Ö—É–∂–µ —Å—Ç–∞—Ä–æ–π
    
    import onnxruntime as ort
    import numpy as np
    from sklearn.metrics import roc_auc_score, accuracy_score
    import pandas as pd
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    test_data = pd.read_csv('data/processed/test.csv')
    X_test = test_data.drop('default', axis=1).values.astype(np.float32)
    y_test = test_data['default'].values
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å
    session = ort.InferenceSession('models/optimization/credit_scoring_quantized.onnx')
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    predictions = session.run(None, {'input': X_test})[0]
    y_pred = (predictions >= 0.5).astype(int).flatten()
    
    # –ú–µ—Ç—Ä–∏–∫–∏
    accuracy = accuracy_score(y_test, y_pred)
    auc = roc_auc_score(y_test, predictions)
    
    logging.info(f"New model metrics:")
    logging.info(f"  Accuracy: {accuracy:.4f}")
    logging.info(f"  AUC: {auc:.4f}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Ä–æ–≥–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    min_accuracy = 0.75
    min_auc = 0.80
    
    if accuracy < min_accuracy or auc < min_auc:
        raise ValueError(f"Model performance below threshold! Accuracy: {accuracy:.4f}, AUC: {auc:.4f}")
    
    logging.info("Model validation passed ‚úÖ")
    
    context['task_instance'].xcom_push(key='accuracy', value=accuracy)
    context['task_instance'].xcom_push(key='auc', value=auc)
    
    return {'accuracy': accuracy, 'auc': auc}


validate_model_task = PythonOperator(
    task_id='validate_model',
    python_callable=validate_model,
    dag=dag,
)


# ============================================
# Task 8: A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
# ============================================

def setup_ab_test(**context):
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ A/B —Ç–µ—Å—Ç–∞ –¥–ª—è –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏"""
    logging.info("Setting up A/B test...")
    
    # –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ª–æ–≥–∏–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ A/B —Ç–µ—Å—Ç–∞
    # –ù–∞–ø—Ä–∏–º–µ—Ä, –¥–µ–ø–ª–æ–π –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏ —Å routing 10% —Ç—Ä–∞—Ñ–∏–∫–∞
    
    logging.info("A/B test configured: 10% traffic to new model")
    
    return True


ab_test_task = PythonOperator(
    task_id='setup_ab_test',
    python_callable=setup_ab_test,
    dag=dag,
)


# ============================================
# Task 9: –î–µ–ø–ª–æ–π –≤ production
# ============================================

deploy_model_task = KubernetesPodOperator(
    task_id='deploy_to_production',
    name='model-deployment-job',
    namespace='default',
    image='bitnami/kubectl:latest',
    cmds=['kubectl'],
    arguments=[
        'set', 'image',
        'deployment/credit-scoring-api',
        'credit-scoring-api=ghcr.io/your-username/credit-scoring-api:latest',
        '-n', 'production'
    ],
    labels={'app': 'model-deployment'},
    get_logs=True,
    is_delete_operator_pod=True,
    dag=dag,
)


# ============================================
# Task 10: –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø–æ—Å–ª–µ –¥–µ–ø–ª–æ—è
# ============================================

def monitor_deployment(**context):
    """–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø–æ—Å–ª–µ –¥–µ–ø–ª–æ—è"""
    logging.info("Monitoring deployment...")
    
    import time
    
    # –ñ–¥–µ–º —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏
    time.sleep(60)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
    # –í —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –∑–¥–µ—Å—å –∑–∞–ø—Ä–æ—Å—ã –∫ Prometheus
    
    logging.info("Deployment monitoring completed ‚úÖ")
    
    return True


monitor_task = PythonOperator(
    task_id='monitor_deployment',
    python_callable=monitor_deployment,
    dag=dag,
)


# ============================================
# Task 11: –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ
# ============================================

def send_notification(**context):
    """–û—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏"""
    logging.info("Sending notification...")
    
    # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –∑–∞–¥–∞—á
    drift_score = context['task_instance'].xcom_pull(task_ids='check_drift', key='drift_score')
    accuracy = context['task_instance'].xcom_pull(task_ids='validate_model', key='accuracy')
    auc = context['task_instance'].xcom_pull(task_ids='validate_model', key='auc')
    
    message = f"""
    ‚úÖ Model Retraining Completed Successfully!
    
    üìä Metrics:
    - Drift Score: {drift_score:.2%}
    - New Model Accuracy: {accuracy:.4f}
    - New Model AUC: {auc:.4f}
    
    üöÄ New model deployed to production
    """
    
    logging.info(message)
    
    # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –æ—Ç–ø—Ä–∞–≤–∫—É –≤ Slack/Telegram
    
    return message


notify_task = PythonOperator(
    task_id='send_notification',
    python_callable=send_notification,
    dag=dag,
)


# ============================================
# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –∑–∞–¥–∞—á
# ============================================

# –õ–∏–Ω–µ–π–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω
(
    check_drift_task
    >> fetch_data_task
    >> validate_data_task
    >> train_model_task
    >> convert_onnx_task
    >> optimize_model_task
    >> validate_model_task
    >> ab_test_task
    >> deploy_model_task
    >> monitor_task
    >> notify_task
)


# ============================================
# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ DAG –¥–ª—è —Ç—Ä–∏–≥–µ—Ä–æ–≤
# ============================================

# DAG –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –¥—Ä–∏—Ñ—Ç–∞ (–∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –∫–∞–∂–¥—ã–π –¥–µ–Ω—å)
drift_monitoring_dag = DAG(
    'credit_scoring_drift_monitoring',
    default_args=default_args,
    description='Daily drift monitoring',
    schedule_interval='@daily',
    start_date=days_ago(1),
    catchup=False,
    tags=['ml', 'credit-scoring', 'monitoring'],
)


def monitor_drift_daily(**context):
    """–ï–∂–µ–¥–Ω–µ–≤–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –¥—Ä–∏—Ñ—Ç–∞"""
    from monitoring.evidently.drift_detection import DriftMonitor
    
    monitor = DriftMonitor(
        reference_data_path='data/processed/train.csv',
        current_data_path='data/processed/current.csv'
    )
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç—ã
    monitor.generate_data_drift_report()
    monitor.generate_target_drift_report()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
    should_retrain = monitor.should_retrain(drift_threshold=0.3)
    
    if should_retrain:
        logging.warning("‚ö†Ô∏è  Drift threshold exceeded! Triggering retraining...")
        # –¢—Ä–∏–≥–≥–µ—Ä–∏–º –æ—Å–Ω–æ–≤–Ω–æ–π DAG –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
        # –í —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è TriggerDagRunOperator
    
    return should_retrain


drift_monitor_task = PythonOperator(
    task_id='monitor_drift',
    python_callable=monitor_drift_daily,
    dag=drift_monitoring_dag,
)
