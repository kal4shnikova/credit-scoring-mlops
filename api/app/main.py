"""
FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –∫—Ä–µ–¥–∏—Ç–Ω–æ–≥–æ —Å–∫–æ—Ä–∏–Ω–≥–∞
Production-ready API —Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º –∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
"""

from fastapi import FastAPI, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field, validator
from typing import List, Optional
import onnxruntime as ort
import numpy as np
import joblib
import logging
from datetime import datetime
import os

# Prometheus metrics
from prometheus_client import Counter, Histogram, Gauge, generate_latest, CONTENT_TYPE_LATEST
from fastapi.responses import Response
import time

# ============================================
# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
# ============================================

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# –ü—É—Ç–∏ –∫ –º–æ–¥–µ–ª—è–º
MODEL_PATH = os.path.join(os.path.dirname(os.path.abspath(__file__)), '../../models/optimization/credit_scoring_quantized.onnx')
SCALER_PATH = os.path.join(os.path.dirname(os.path.abspath(__file__)), '../../models/trained/scaler.pkl')

# ============================================
# Prometheus Metrics
# ============================================

# –°—á–µ—Ç—á–∏–∫–∏ –∑–∞–ø—Ä–æ—Å–æ–≤
request_count = Counter(
    'credit_scoring_requests_total',
    'Total number of prediction requests',
    ['status']
)

# –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –≤—Ä–µ–º–µ–Ω–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
request_duration = Histogram(
    'credit_scoring_request_duration_seconds',
    'Request duration in seconds',
    buckets=[0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0]
)

# –°—á–µ—Ç—á–∏–∫ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –ø–æ –∫–ª–∞—Å—Å–∞–º
prediction_counter = Counter(
    'credit_scoring_predictions_total',
    'Total predictions by class',
    ['prediction']
)

# Gauge –¥–ª—è –∞–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
active_requests = Gauge(
    'credit_scoring_active_requests',
    'Number of active prediction requests'
)

# ============================================
# Pydantic Models
# ============================================

class CreditApplication(BaseModel):
    """–ó–∞—è–≤–∫–∞ –Ω–∞ –∫—Ä–µ–¥–∏—Ç"""
    
    age: int = Field(..., ge=18, le=100, description="–í–æ–∑—Ä–∞—Å—Ç –∑–∞–µ–º—â–∏–∫–∞")
    income: float = Field(..., gt=0, description="–ì–æ–¥–æ–≤–æ–π –¥–æ—Ö–æ–¥")
    loan_amount: float = Field(..., gt=0, description="–ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º–∞—è —Å—É–º–º–∞ –∫—Ä–µ–¥–∏—Ç–∞")
    credit_history_length: int = Field(..., ge=0, le=50, description="–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫—Ä–µ–¥–∏—Ç–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–∏ (–ª–µ—Ç)")
    num_open_accounts: int = Field(..., ge=0, le=50, description="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∫—Ä—ã—Ç—ã—Ö —Å—á–µ—Ç–æ–≤")
    debt_to_income: float = Field(..., ge=0, le=1, description="–û—Ç–Ω–æ—à–µ–Ω–∏–µ –¥–æ–ª–≥–∞ –∫ –¥–æ—Ö–æ–¥—É")
    num_late_payments: int = Field(..., ge=0, le=100, description="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Å—Ä–æ—á–µ–Ω–Ω—ã—Ö –ø–ª–∞—Ç–µ–∂–µ–π")
    employment_length: int = Field(..., ge=0, le=50, description="–°—Ç–∞–∂ —Ä–∞–±–æ—Ç—ã (–ª–µ—Ç)")
    num_credit_inquiries: int = Field(..., ge=0, le=50, description="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫—Ä–µ–¥–∏—Ç–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤")
    credit_utilization: float = Field(..., ge=0, le=1, description="–ü—Ä–æ—Ü–µ–Ω—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫—Ä–µ–¥–∏—Ç–∞")
    
    @validator('debt_to_income', 'credit_utilization')
    def check_ratio(cls, v):
        if v < 0 or v > 1:
            raise ValueError('–ó–Ω–∞—á–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –º–µ–∂–¥—É 0 –∏ 1')
        return v
    
    class Config:
        schema_extra = {
            "example": {
                "age": 35,
                "income": 60000,
                "loan_amount": 15000,
                "credit_history_length": 10,
                "num_open_accounts": 5,
                "debt_to_income": 0.3,
                "num_late_payments": 0,
                "employment_length": 8,
                "num_credit_inquiries": 2,
                "credit_utilization": 0.4
            }
        }


class BatchCreditApplications(BaseModel):
    """–ë–∞—Ç—á –∑–∞—è–≤–æ–∫ –Ω–∞ –∫—Ä–µ–¥–∏—Ç"""
    applications: List[CreditApplication]


class PredictionResponse(BaseModel):
    """–û—Ç–≤–µ—Ç —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ–º"""
    
    prediction: int = Field(..., description="0 - –æ–¥–æ–±—Ä–µ–Ω–æ, 1 - –æ—Ç–∫–∞–∑–∞–Ω–æ")
    probability: float = Field(..., description="–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –¥–µ—Ñ–æ–ª—Ç–∞")
    risk_level: str = Field(..., description="–£—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞: low, medium, high")
    timestamp: str = Field(..., description="–í—Ä–µ–º—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è")
    model_version: str = Field(..., description="–í–µ—Ä—Å–∏—è –º–æ–¥–µ–ª–∏")


class BatchPredictionResponse(BaseModel):
    """–û—Ç–≤–µ—Ç —Å –±–∞—Ç—á –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏"""
    predictions: List[PredictionResponse]
    batch_size: int


class HealthResponse(BaseModel):
    """–°—Ç–∞—Ç—É—Å –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–∏—Å–∞"""
    status: str
    model_loaded: bool
    scaler_loaded: bool
    timestamp: str


# ============================================
# Model Loader
# ============================================

class ModelManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –º–æ–¥–µ–ª—è–º–∏"""
    
    def __init__(self):
        self.session = None
        self.scaler = None
        self.model_version = "1.0.0"
        self.load_model()
    
    def load_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ ONNX –º–æ–¥–µ–ª–∏ –∏ scaler"""
        try:
            # –ó–∞–≥—Ä—É–∑–∫–∞ ONNX –º–æ–¥–µ–ª–∏
            logger.info(f"Loading ONNX model from: {MODEL_PATH}")
            self.session = ort.InferenceSession(MODEL_PATH)
            logger.info("‚úÖ ONNX model loaded successfully")
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ scaler
            logger.info(f"Loading scaler from: {SCALER_PATH}")
            self.scaler = joblib.load(SCALER_PATH)
            logger.info("‚úÖ Scaler loaded successfully")
            
        except Exception as e:
            logger.error(f"‚ùå Error loading model: {e}")
            raise
    
    def preprocess(self, data: np.ndarray) -> np.ndarray:
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
        return self.scaler.transform(data).astype(np.float32)
    
    def predict(self, data: np.ndarray) -> np.ndarray:
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ"""
        input_name = self.session.get_inputs()[0].name
        return self.session.run(None, {input_name: data})[0]
    
    def get_risk_level(self, probability: float) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è —Ä–∏—Å–∫–∞"""
        if probability < 0.3:
            return "low"
        elif probability < 0.7:
            return "medium"
        else:
            return "high"


# ============================================
# FastAPI App
# ============================================

app = FastAPI(
    title="Credit Scoring API",
    description="Production ML API for credit scoring with ONNX model",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
model_manager = ModelManager()


# ============================================
# Middleware –¥–ª—è –º–µ—Ç—Ä–∏–∫
# ============================================

@app.middleware("http")
async def track_requests(request, call_next):
    """Middleware –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –º–µ—Ç—Ä–∏–∫"""
    
    # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –∞–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
    active_requests.inc()
    
    # –ó–∞—Å–µ–∫–∞–µ–º –≤—Ä–µ–º—è
    start_time = time.time()
    
    try:
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∑–∞–ø—Ä–æ—Å
        response = await call_next(request)
        
        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
        duration = time.time() - start_time
        request_duration.observe(duration)
        request_count.labels(status=response.status_code).inc()
        
        return response
    
    finally:
        # –£–º–µ–Ω—å—à–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –∞–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        active_requests.dec()


# ============================================
# Endpoints
# ============================================

@app.get("/", tags=["Root"])
async def root():
    """–ö–æ—Ä–Ω–µ–≤–æ–π endpoint"""
    return {
        "message": "Credit Scoring API",
        "version": "1.0.0",
        "docs": "/docs",
        "health": "/health",
        "metrics": "/metrics"
    }


@app.get("/health", response_model=HealthResponse, tags=["Health"])
async def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–∏—Å–∞"""
    return HealthResponse(
        status="healthy",
        model_loaded=model_manager.session is not None,
        scaler_loaded=model_manager.scaler is not None,
        timestamp=datetime.now().isoformat()
    )


@app.get("/metrics", tags=["Monitoring"])
async def metrics():
    """Prometheus –º–µ—Ç—Ä–∏–∫–∏"""
    return Response(
        content=generate_latest(),
        media_type=CONTENT_TYPE_LATEST
    )


@app.post("/predict", response_model=PredictionResponse, tags=["Prediction"])
async def predict_single(application: CreditApplication):
    """
    –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –æ–¥–Ω–æ–π –∑–∞—è–≤–∫–∏
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
    - prediction: 0 (–æ–¥–æ–±—Ä–µ–Ω–æ) –∏–ª–∏ 1 (–æ—Ç–∫–∞–∑–∞–Ω–æ)
    - probability: –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –¥–µ—Ñ–æ–ª—Ç–∞
    - risk_level: —É—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞
    """
    
    try:
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        features = np.array([[
            application.age,
            application.income,
            application.loan_amount,
            application.credit_history_length,
            application.num_open_accounts,
            application.debt_to_income,
            application.num_late_payments,
            application.employment_length,
            application.num_credit_inquiries,
            application.credit_utilization
        ]])
        
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
        features_scaled = model_manager.preprocess(features)
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        probability = model_manager.predict(features_scaled)[0][0]
        prediction = int(probability >= 0.5)
        risk_level = model_manager.get_risk_level(probability)
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
        prediction_counter.labels(prediction=str(prediction)).inc()
        
        logger.info(f"Prediction: {prediction}, Probability: {probability:.4f}")
        
        return PredictionResponse(
            prediction=prediction,
            probability=float(probability),
            risk_level=risk_level,
            timestamp=datetime.now().isoformat(),
            model_version=model_manager.model_version
        )
    
    except Exception as e:
        logger.error(f"Error during prediction: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/predict/batch", response_model=BatchPredictionResponse, tags=["Prediction"])
async def predict_batch(batch: BatchCreditApplications):
    """
    –ë–∞—Ç—á –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∑–∞—è–≤–æ–∫
    
    –ë–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –∑–∞—è–≤–æ–∫ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
    """
    
    try:
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        features = []
        for app in batch.applications:
            features.append([
                app.age,
                app.income,
                app.loan_amount,
                app.credit_history_length,
                app.num_open_accounts,
                app.debt_to_income,
                app.num_late_payments,
                app.employment_length,
                app.num_credit_inquiries,
                app.credit_utilization
            ])
        
        features = np.array(features)
        
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
        features_scaled = model_manager.preprocess(features)
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        probabilities = model_manager.predict(features_scaled)
        
        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–æ–≤
        predictions = []
        for prob in probabilities:
            probability = float(prob[0])
            prediction = int(probability >= 0.5)
            risk_level = model_manager.get_risk_level(probability)
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
            prediction_counter.labels(prediction=str(prediction)).inc()
            
            predictions.append(PredictionResponse(
                prediction=prediction,
                probability=probability,
                risk_level=risk_level,
                timestamp=datetime.now().isoformat(),
                model_version=model_manager.model_version
            ))
        
        logger.info(f"Batch prediction completed for {len(predictions)} applications")
        
        return BatchPredictionResponse(
            predictions=predictions,
            batch_size=len(predictions)
        )
    
    except Exception as e:
        logger.error(f"Error during batch prediction: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/model/info", tags=["Model"])
async def model_info():
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏"""
    return {
        "model_version": model_manager.model_version,
        "model_type": "ONNX Neural Network",
        "optimization": "INT8 Quantization",
        "input_features": 10,
        "output_classes": 2
    }


# ============================================
# Startup/Shutdown Events
# ============================================

@app.on_event("startup")
async def startup_event():
    """–î–µ–π—Å—Ç–≤–∏—è –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    logger.info("üöÄ Starting Credit Scoring API...")
    logger.info(f"Model version: {model_manager.model_version}")
    logger.info("‚úÖ API is ready to accept requests")


@app.on_event("shutdown")
async def shutdown_event():
    """–î–µ–π—Å—Ç–≤–∏—è –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    logger.info("Shutting down Credit Scoring API...")


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
