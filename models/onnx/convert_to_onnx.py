"""
–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è PyTorch –º–æ–¥–µ–ª–∏ –≤ ONNX —Ñ–æ—Ä–º–∞—Ç
–≠—Ç–∞–ø 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –º–æ–¥–µ–ª–∏ –∫ –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–æ–π —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–∏
"""

import torch
import onnx
import onnxruntime as ort
import numpy as np
import time
import joblib
from pathlib import Path

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å –∏–∑ train_nn.py
import sys
sys.path.append('../training')
from train_nn import CreditScoringNN

# –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
Path("../../models/onnx").mkdir(parents=True, exist_ok=True)


def convert_to_onnx(model_path, onnx_path, input_size=10):
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è PyTorch –º–æ–¥–µ–ª–∏ –≤ ONNX —Ñ–æ—Ä–º–∞—Ç
    
    Args:
        model_path: –ø—É—Ç—å –∫ PyTorch –º–æ–¥–µ–ª–∏ (.pth)
        onnx_path: –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è ONNX –º–æ–¥–µ–ª–∏ (.onnx)
        input_size: —Ä–∞–∑–º–µ—Ä –≤—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞ (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ features)
    """
    
    print("üîÑ –ù–∞—á–∏–Ω–∞–µ–º –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—é –≤ ONNX...")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ PyTorch –º–æ–¥–µ–ª–∏
    model = torch.load(model_path, map_location='cpu')
    model.eval()
    
    # –°–æ–∑–¥–∞–µ–º dummy input –¥–ª—è —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏
    dummy_input = torch.randn(1, input_size)
    
    # –≠–∫—Å–ø–æ—Ä—Ç –≤ ONNX
    torch.onnx.export(
        model,                          # –º–æ–¥–µ–ª—å
        dummy_input,                     # –ø—Ä–∏–º–µ—Ä –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        onnx_path,                       # –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        export_params=True,              # —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤–µ—Å–∞
        opset_version=12,                # –≤–µ—Ä—Å–∏—è ONNX opset
        do_constant_folding=True,        # –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Å—Ç–∞–Ω—Ç–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
        input_names=['input'],           # –∏–º—è –≤—Ö–æ–¥–∞
        output_names=['output'],         # –∏–º—è –≤—ã—Ö–æ–¥–∞
        dynamic_axes={                   # –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ —Ä–∞–∑–º–µ—Ä—ã
            'input': {0: 'batch_size'},
            'output': {0: 'batch_size'}
        }
    )
    
    print(f"‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞: {onnx_path}")
    
    return onnx_path


def validate_onnx(onnx_path):
    """
    –í–∞–ª–∏–¥–∞—Ü–∏—è ONNX –º–æ–¥–µ–ª–∏
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –º–æ–¥–µ–ª–∏
    """
    
    print("\nüîç –í–∞–ª–∏–¥–∞—Ü–∏—è ONNX –º–æ–¥–µ–ª–∏...")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ ONNX –º–æ–¥–µ–ª–∏
    onnx_model = onnx.load(onnx_path)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏
    try:
        onnx.checker.check_model(onnx_model)
        print("‚úÖ ONNX –º–æ–¥–µ–ª—å –≤–∞–ª–∏–¥–Ω–∞!")
    except onnx.checker.ValidationError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")
        return False
    
    # –í—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏
    print("\nüìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏:")
    print(f"  IR Version: {onnx_model.ir_version}")
    print(f"  Producer: {onnx_model.producer_name}")
    print(f"  Graph nodes: {len(onnx_model.graph.node)}")
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤—Ö–æ–¥–∞—Ö –∏ –≤—ã—Ö–æ–¥–∞—Ö
    print("\n  –í—Ö–æ–¥—ã:")
    for input_tensor in onnx_model.graph.input:
        print(f"    - {input_tensor.name}: {input_tensor.type}")
    
    print("\n  –í—ã—Ö–æ–¥—ã:")
    for output_tensor in onnx_model.graph.output:
        print(f"    - {output_tensor.name}: {output_tensor.type}")
    
    return True


def compare_outputs(pytorch_model_path, onnx_path, test_data, scaler_path):
    """
    –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—ã—Ö–æ–¥–æ–≤ PyTorch –∏ ONNX –º–æ–¥–µ–ª–µ–π
    –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
    """
    
    print("\nüî¨ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—ã—Ö–æ–¥–æ–≤ PyTorch vs ONNX...")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π
    pytorch_model = torch.load(pytorch_model_path, map_location='cpu')
    pytorch_model.eval()
    
    ort_session = ort.InferenceSession(onnx_path)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ scaler
    scaler = joblib.load(scaler_path)
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    test_data_scaled = scaler.transform(test_data)
    test_tensor = torch.FloatTensor(test_data_scaled)
    
    # PyTorch inference
    with torch.no_grad():
        pytorch_output = pytorch_model(test_tensor).numpy()
    
    # ONNX inference
    onnx_output = ort_session.run(
        None,
        {'input': test_data_scaled.astype(np.float32)}
    )[0]
    
    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ
    max_diff = np.max(np.abs(pytorch_output - onnx_output))
    mean_diff = np.mean(np.abs(pytorch_output - onnx_output))
    
    print(f"  –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ä–∞–∑–Ω–∏—Ü–∞: {max_diff:.10f}")
    print(f"  –°—Ä–µ–¥–Ω—è—è —Ä–∞–∑–Ω–∏—Ü–∞: {mean_diff:.10f}")
    
    if max_diff < 1e-5:
        print("‚úÖ –í—ã—Ö–æ–¥—ã –∏–¥–µ–Ω—Ç–∏—á–Ω—ã! –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ.")
        return True
    else:
        print("‚ö†Ô∏è  –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Ä–∞–∑–ª–∏—á–∏—è –≤ –≤—ã—Ö–æ–¥–∞—Ö.")
        return False


def benchmark_performance(pytorch_model_path, onnx_path, test_data, scaler_path, n_runs=1000):
    """
    –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ PyTorch vs ONNX
    –ó–∞–º–µ—Ä –≤—Ä–µ–º–µ–Ω–∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –Ω–∞ CPU
    """
    
    print(f"\n‚ö° Benchmark –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ ({n_runs} –∏—Ç–µ—Ä–∞—Ü–∏–π)...")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π
    pytorch_model = torch.load(pytorch_model_path, map_location='cpu')
    pytorch_model.eval()
    
    ort_session = ort.InferenceSession(onnx_path)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ scaler
    scaler = joblib.load(scaler_path)
    test_data_scaled = scaler.transform(test_data)
    
    # –ü—Ä–æ–≥—Ä–µ–≤ (warm-up)
    test_tensor = torch.FloatTensor(test_data_scaled)
    with torch.no_grad():
        _ = pytorch_model(test_tensor)
    _ = ort_session.run(None, {'input': test_data_scaled.astype(np.float32)})
    
    # PyTorch benchmark
    pytorch_times = []
    for _ in range(n_runs):
        start = time.perf_counter()
        with torch.no_grad():
            _ = pytorch_model(test_tensor)
        pytorch_times.append(time.perf_counter() - start)
    
    # ONNX benchmark
    onnx_times = []
    for _ in range(n_runs):
        start = time.perf_counter()
        _ = ort_session.run(None, {'input': test_data_scaled.astype(np.float32)})
        onnx_times.append(time.perf_counter() - start)
    
    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
    pytorch_mean = np.mean(pytorch_times) * 1000  # –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö
    pytorch_std = np.std(pytorch_times) * 1000
    onnx_mean = np.mean(onnx_times) * 1000
    onnx_std = np.std(onnx_times) * 1000
    
    speedup = pytorch_mean / onnx_mean
    
    print("\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
    print(f"  PyTorch:")
    print(f"    –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {pytorch_mean:.4f} ¬± {pytorch_std:.4f} ms")
    print(f"  ONNX:")
    print(f"    –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {onnx_mean:.4f} ¬± {onnx_std:.4f} ms")
    print(f"  –£—Å–∫–æ—Ä–µ–Ω–∏–µ: {speedup:.2f}x")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    results = {
        'pytorch_mean_ms': pytorch_mean,
        'pytorch_std_ms': pytorch_std,
        'onnx_mean_ms': onnx_mean,
        'onnx_std_ms': onnx_std,
        'speedup': speedup,
        'n_runs': n_runs
    }
    
    import json
    with open('../../models/onnx/benchmark_results.json', 'w') as f:
        json.dump(results, f, indent=2)
    
    return results


def get_model_size(model_path):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –º–æ–¥–µ–ª–∏ –≤ –ú–ë"""
    import os
    size_mb = os.path.getsize(model_path) / (1024 * 1024)
    return size_mb


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
    
    print("=" * 60)
    print("–ö–û–ù–í–ï–†–¢–ê–¶–ò–Ø –ú–û–î–ï–õ–ò –í ONNX –§–û–†–ú–ê–¢")
    print("=" * 60)
    
    # –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º
    PYTORCH_MODEL = '../../models/trained/credit_scoring_nn.pth'
    ONNX_MODEL = '../../models/onnx/credit_scoring_model.onnx'
    SCALER_PATH = '../../models/trained/scaler.pkl'
    INPUT_SIZE = 10
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è PyTorch –º–æ–¥–µ–ª–∏
    import os
    if not os.path.exists(PYTORCH_MODEL):
        print(f"‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {PYTORCH_MODEL}")
        print("–°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ: python models/training/train_nn.py")
        return
    
    # 1. –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ ONNX
    convert_to_onnx(PYTORCH_MODEL, ONNX_MODEL, input_size=INPUT_SIZE)
    
    # 2. –í–∞–ª–∏–¥–∞—Ü–∏—è ONNX
    if not validate_onnx(ONNX_MODEL):
        print("‚ùå –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–µ –ø—Ä–æ–π–¥–µ–Ω–∞!")
        return
    
    # 3. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–æ–≤ –º–æ–¥–µ–ª–µ–π
    print("\nüì¶ –†–∞–∑–º–µ—Ä—ã –º–æ–¥–µ–ª–µ–π:")
    pytorch_size = get_model_size(PYTORCH_MODEL)
    onnx_size = get_model_size(ONNX_MODEL)
    print(f"  PyTorch: {pytorch_size:.2f} MB")
    print(f"  ONNX: {onnx_size:.2f} MB")
    print(f"  –†–∞–∑–Ω–∏—Ü–∞: {((onnx_size - pytorch_size) / pytorch_size * 100):+.1f}%")
    
    # 4. –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    np.random.seed(42)
    test_data = np.random.randn(100, INPUT_SIZE)
    
    # 5. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—ã—Ö–æ–¥–æ–≤
    compare_outputs(PYTORCH_MODEL, ONNX_MODEL, test_data, SCALER_PATH)
    
    # 6. Benchmark –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    benchmark_performance(PYTORCH_MODEL, ONNX_MODEL, test_data, SCALER_PATH)
    
    print("\n" + "=" * 60)
    print("‚úÖ –ö–û–ù–í–ï–†–¢–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê –£–°–ü–ï–®–ù–û!")
    print("=" * 60)
    print(f"\nüìÅ –§–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã:")
    print(f"  - ONNX –º–æ–¥–µ–ª—å: {ONNX_MODEL}")
    print(f"  - –†–µ–∑—É–ª—å—Ç–∞—Ç—ã benchmark: models/onnx/benchmark_results.json")
    print("\nüí° –°–ª–µ–¥—É—é—â–∏–π —à–∞–≥: –∑–∞–ø—É—Å—Ç–∏—Ç–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –º–æ–¥–µ–ª–∏")
    print("   python models/optimization/quantize.py")


if __name__ == "__main__":
    main()
